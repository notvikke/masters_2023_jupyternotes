{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "864e3c9e",
   "metadata": {},
   "source": [
    "<table border=\"0\" style=\"width:100%\">\n",
    " <tr>\n",
    "    <td>\n",
    "        <img src=\"https://static-frm.ie.edu/university/wp-content/uploads/sites/6/2022/06/IE-University-logo.png\" width=150>\n",
    "     </td>\n",
    "    <td><div style=\"font-family:'Courier New'\">\n",
    "            <div style=\"font-size:25px\">\n",
    "                <div style=\"text-align: right\"> \n",
    "                    <b> MASTER IN BIG DATA</b>\n",
    "                    <br>\n",
    "                    Python for Data Analysis II\n",
    "                    <br><br>\n",
    "                    <em> Daniel Sierra Ramos </em>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </td>\n",
    " </tr>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e1d512b",
   "metadata": {},
   "source": [
    "# **S09: ROBUSTNESS - CROSS VALIDATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7fd86f7-34d1-4330-85ff-151e25ccbeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"none\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "019c0391",
   "metadata": {},
   "source": [
    "# The train-test split is not flawless\n",
    "\n",
    "- When we tackle a machine learning problem, one of the most important operations we do is splitting the data into a **training set** and a **test set**.\n",
    "    - Train Set - Used to train the model\n",
    "    - Test Set - Used to evaluate the model\n",
    "- We use this split to **avoid overfitting**, that is, to avoid that the model learns too much from the training data, and therefore, it doesn't generalize well on unseen data.\n",
    "\n",
    "**However, the train-test split is too simple and it's not enough**\n",
    "\n",
    "<center><img src=\"https://d33wubrfki0l68.cloudfront.net/c39b2d19183ed14141a8b7b03943442d40efee0d/81e2a/wp-content/uploads/2019/03/train_test_split.png\" width=\"700\"/></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fd2b20f",
   "metadata": {},
   "source": [
    "### When *hyperparameters* come into play"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ef197bd",
   "metadata": {},
   "source": [
    "- When we **adjust the hyperparameters of the model**, let's say the regularization strength or the depth in a Decision Tree model, we inevitably tend to use the **test set** to *tweak the hyperparamenters* in order to obtain the best results as possible in the test set.\n",
    "> Be careful!: Doing this automatically turns the test set in **seen data**, not **unseen data**. At the emd, we're using the test set to train (\"improve\") the model.\n",
    "\n",
    "- To solve this problem, we can use another set to validate the hyperparameters called **validation set**. This set can be used to validate the hyperparamenters, and then, we use the test set to evaluate the model with **real unseen data**.\n",
    "\n",
    "<center><img src=\"https://cdn.shortpixel.ai/spai/q_lossy+w_730+to_webp+ret_img/https://algotrading101.com/learn/wp-content/uploads/2020/06/training-validation-test-data-set.png\" width=\"700\"/></center>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a8960b8",
   "metadata": {},
   "source": [
    "### Right, but now I have less data for training :(\n",
    "\n",
    "- Having a validation set reduces the amount of data we have to train the model. This can compromise the model's performance, especially if we have a small dataset.\n",
    "\n",
    "- Also, having just a validation set still have one unresolved problem: Is my model robust if trained on different sets of data?\n",
    "\n",
    "To solve all this problems, we can use **cross-validation**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbe0f8e1-acdb-4a02-9f6f-7d37705657ef",
   "metadata": {},
   "source": [
    "# **Cross-Validation**: Building robust models\n",
    "\n",
    " - The **cross validation** is a technique commonly used in machine learning to measure the robustness of a model, and in essence, to measure the bias and variance. Have a look to this article: https://codesachin.wordpress.com/2015/08/30/cross-validation-and-the-bias-variance-tradeoff-for-dummies/\n",
    "\n",
    " - Also, the CV strategy is used for **hyperparameter tuning** in order to find the best set of hyperparameters for the model.\n",
    "\n",
    " - It consists on creating a new set of data called the **validation set** in order to test the model robustness in several training settings with different data.\n",
    "\n",
    " - The most relevant cross validation strategies are **K-Fold CV** and **Leave-One-Out CV**.\n",
    "\n",
    " - **Cross-validation** has become a standard in the ML process, and **is part of the general set up in a machine learning model design**. So, it's important to know how to use it.\n",
    "\n",
    "<center><img src=\"https://elitedatascience.com/wp-content/uploads/2017/06/Train-Test-Split-Diagram.jpg\" width=\"700\"/></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0d2867c",
   "metadata": {},
   "source": [
    "### **K-Fold CV**\n",
    "\n",
    "Consists on dividing the training data in $K$ folds, and create $K$ models rotating the set of data we use for training. The typical setting is: use $k-1$ folds for training and the last one for validation. Then repeat rotating the validation set.\n",
    "\n",
    "<center><img src=\"https://miro.medium.com/max/720/1*qPMFLEbvc8QQf38Cf77wQg.png\" width=\"700\"/></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "544b1e4f",
   "metadata": {},
   "source": [
    "### **Leave-One-Out CV**\n",
    "\n",
    "It's the extrema version of K-Fold. Consists on using $N-1$ samples for training and the last one for validation. Then repeat rotating the validation set. That is, the number of folds is equal to the number of samples in the dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "914df066-aed6-41de-bb01-fe3b627556df",
   "metadata": {},
   "source": [
    "## Cross-Validation in `scikit-learn`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "164d2d90",
   "metadata": {},
   "source": [
    "### The `cross_val_score` function\n",
    "\n",
    "Given a trained model, the `cross_val_score` function allows us to evaluate the model using cross-validation. It takes as input the model, the data, the target, and the number of folds. It returns the score of the model in each fold.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5e4e564-7e48-4fa5-b3f2-80e9dfbc4cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f04b55be-e337-406f-ae87-6748c74c411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f7960ad",
   "metadata": {},
   "source": [
    "Let's evaluate a SVM model using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0bd1096-4475-4a45-bca7-435c28399841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate on test set\n",
    "clf = SVC(kernel='linear', C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c48ad5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93181818, 0.95348837, 0.97560976, 0.95348837, 0.93333333])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evalute ion training set\n",
    "cross_val_score(clf, X_train, y_train, cv=5, scoring=\"precision\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae38fa75-23f3-4553-8fdf-82324e4278e7",
   "metadata": {},
   "source": [
    "By default, the `cross_val_score` is training the model on the different folds and then calculating the `precision` with the holdout set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8d52bef",
   "metadata": {},
   "source": [
    "Now, let's evaluate the model using the `recall` metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8be20ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95348837, 0.95348837, 0.95238095, 0.97619048, 1.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evalute ion training set\n",
    "cross_val_score(clf, X_train, y_train, cv=5, scoring=\"recall\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b601f715",
   "metadata": {},
   "source": [
    "Now, let's use the LOO strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62d6cc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5135cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(341, 30)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b47d7958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOO taks too much time because it's to fit 341 models. Let's reduce the dataset to 20 sample to illustrate this example\n",
    "X_train_red = X_train[:20]\n",
    "y_train_red = y_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0baa3886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 1.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X_train_red, y_train_red, cv=LeaveOneOut(), scoring=\"accuracy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "233e6bed",
   "metadata": {},
   "source": [
    "### Let's rock with the `cross_validate` function.\n",
    "\n",
    "The ``cross_validate`` function is similar to the ``cross_val_score`` function, but it allows us to use different metrics and to return the training time and training scores.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scores = cross_validate(model, X, y, cv=5, scoring=['precision', 'recall'], return_train_score=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d0f1002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b70dfe14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.2752738 , 0.34882474, 0.17294383, 0.33057857, 0.20749354]),\n",
       " 'score_time': array([0.00152445, 0.00146008, 0.00151134, 0.00153732, 0.00178981]),\n",
       " 'test_precision': array([0.93181818, 0.95348837, 0.97560976, 0.95348837, 0.93333333]),\n",
       " 'train_precision': array([0.96511628, 0.96511628, 0.97660819, 0.96551724, 0.98214286]),\n",
       " 'test_recall': array([0.95348837, 0.95348837, 0.95238095, 0.97619048, 1.        ]),\n",
       " 'train_recall': array([0.98224852, 0.98224852, 0.98235294, 0.98823529, 0.97058824])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = cross_validate(clf, X_train, y_train, cv=5, scoring=['precision', 'recall'], return_train_score=True)\n",
    "\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3996e4c6",
   "metadata": {},
   "source": [
    "We can transform the dictionary into a dataframe and calculate the mean and standard deviation of the scores to evaluate the general performance of the model. The optimum result is:\n",
    "- *Train and test scores are **very similar***\n",
    "- *The average of the scores is **high***\n",
    "- *The standard deviation of the scores is **low***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48f28e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.275274</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.965116</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.982249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.348825</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.965116</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.982249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.172944</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.976608</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.982353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.330579</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.988235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.207494</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_precision  train_precision  test_recall  \\\n",
       "0  0.275274    0.001524        0.931818         0.965116     0.953488   \n",
       "1  0.348825    0.001460        0.953488         0.965116     0.953488   \n",
       "2  0.172944    0.001511        0.975610         0.976608     0.952381   \n",
       "3  0.330579    0.001537        0.953488         0.965517     0.976190   \n",
       "4  0.207494    0.001790        0.933333         0.982143     1.000000   \n",
       "\n",
       "   train_recall  \n",
       "0      0.982249  \n",
       "1      0.982249  \n",
       "2      0.982353  \n",
       "3      0.988235  \n",
       "4      0.970588  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9f3018be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time           0.267023\n",
       "score_time         0.001565\n",
       "test_precision     0.949548\n",
       "train_precision    0.970900\n",
       "test_recall        0.967110\n",
       "train_recall       0.981135\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3fc6ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time           0.076147\n",
       "score_time         0.000129\n",
       "test_precision     0.017941\n",
       "train_precision    0.007982\n",
       "test_recall        0.020930\n",
       "train_recall       0.006435\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.std()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07206ecf",
   "metadata": {},
   "source": [
    "## Other cross-validation strategies\n",
    "\n",
    "### **Stratified K-Fold**\n",
    "\n",
    "The K-Fold CV is not always the best option. For example, if we have a dataset with a high class imbalance, the K-Fold CV can lead to a model that is not able to generalize well on the minority class. To solve this problem, we can use the **Stratified K-Fold CV**. This strategy ensures that the proportion of each class is the same in each fold.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "```\n",
    "\n",
    "### **Group K-Fold**\n",
    "\n",
    "The Group K-Fold CV is used when we have a dataset with groups. For example, if we have a dataset with several patients, and we want to predict the disease progression of each patient, we can use the Group K-Fold CV to ensure that the model is trained with data from the same patient in the training set and in the validation set.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "```\n",
    "\n",
    "### **Time Series Split**\n",
    "\n",
    "The Time Series Split CV is used when we have a time series dataset. For example, if we have a dataset with the stock price of a company, we can use the Time Series Split CV to ensure that the model is trained with data from the past and validated with data from the future.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82e68c91",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "\n",
    "Once we have evaluated the model using cross-validation, we need to **train** the final model with the **entire training set** and **evaluate** it with the **test set**. This is the final step of the ML process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DATASCIENCE (Python 3.10)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
