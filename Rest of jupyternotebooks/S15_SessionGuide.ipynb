{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "864e3c9e",
   "metadata": {},
   "source": [
    "<table border=\"0\" style=\"width:100%\">\n",
    " <tr>\n",
    "    <td>\n",
    "        <img src=\"https://static-frm.ie.edu/university/wp-content/uploads/sites/6/2022/06/IE-University-logo.png\" width=150>\n",
    "     </td>\n",
    "    <td><div style=\"font-family:'Courier New'\">\n",
    "            <div style=\"font-size:25px\">\n",
    "                <div style=\"text-align: right\"> \n",
    "                    <b> MASTER IN BIG DATA</b>\n",
    "                    <br>\n",
    "                    Python for Data Analysis II\n",
    "                    <br><br>\n",
    "                    <em> Daniel Sierra Ramos </em>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </td>\n",
    " </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d6180f-8794-4025-a5b2-b2e24f18ce0e",
   "metadata": {},
   "source": [
    "# **S15: PIPELINES**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198f7604-ea64-418a-820e-e29522246d24",
   "metadata": {},
   "source": [
    "One of the problems that usually arise when we build machine learning problems with `scikit-learn` is the fact that we have to concatenate a lot of operations. For example:\n",
    " - one-hot-encoding for categorical variables\n",
    " - imputation of missing values just for some variables\n",
    " - standard scaling of continuous features\n",
    " - training a model on the resulting data\n",
    " \n",
    "Every operation above have its own `fit/transform` operation, and we have to apply all of them in order to the training set for training, and then we have to replicate exactly the same operations if we want to get the results on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668f96e7-01ba-4a0b-9a19-d7b0cd128ab9",
   "metadata": {},
   "source": [
    "## Composite transformers and estimators\n",
    "\n",
    "In `scikit-learn` we have some tools to avoid replicating these structures and calling *fit* of *transform* several times for every operation in the data preprocessing and training steps.\n",
    "\n",
    " - `Pipeline` - To chain several operations that goes consecutively. For example, we can build a pipeline that first fit a `Standardscaler` and then a `LogisticRegression`.\n",
    " - `ColumnTransformer` - This is used to apply specific transformations for every column in the DataFrame independently. For example, we can apply a `OneHotEncoder` to the categorical variables and a `StandardScaler` to the numerical variables and automatically join the result of both operations in a new table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d268238d-bd17-4749-a225-fe2a103ceb53",
   "metadata": {},
   "source": [
    "## **Example: The Adults dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "586ac5f8-ffd7-4234-b5bf-7a570de6ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92e7ebe5-20bc-410b-9d36-d32af2d2a20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b335f80-d37e-4b7a-af1e-73a14acc1282",
   "metadata": {},
   "source": [
    "### **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd612402-b871-456d-893d-80726c1b1b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/adult.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10eee817-c1b9-4591-aba5-2c5073583cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   age              48842 non-null  int64 \n",
      " 1   workclass        48842 non-null  object\n",
      " 2   fnlwgt           48842 non-null  int64 \n",
      " 3   education        48842 non-null  object\n",
      " 4   educational-num  48842 non-null  int64 \n",
      " 5   marital-status   48842 non-null  object\n",
      " 6   occupation       48842 non-null  object\n",
      " 7   relationship     48842 non-null  object\n",
      " 8   race             48842 non-null  object\n",
      " 9   gender           48842 non-null  object\n",
      " 10  capital-gain     48842 non-null  int64 \n",
      " 11  capital-loss     48842 non-null  int64 \n",
      " 12  hours-per-week   48842 non-null  int64 \n",
      " 13  native-country   48842 non-null  object\n",
      " 14  income           48842 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab942d9-49d6-4f17-a95d-7d1dfeae8005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d67212-01f7-4c08-bbe2-5592c49176f1",
   "metadata": {},
   "source": [
    "### 1. Build a `ColumnTransformer` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80b6f0-f1bd-4362-b0b1-da6def39fe02",
   "metadata": {},
   "source": [
    "## **Data Quality**\n",
    "\n",
    "In this part, let's check 2 things:\n",
    " - Missing values -> No missing values in this problem\n",
    " - Data types -> Some data types need to be changed\n",
    "    - `capital_gain` -> `float`\n",
    "    - `capital_loss` -> `float`\n",
    "    - `age` -> `float`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1453b91d-666a-4a00-a333-10c2b5c6ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype({\n",
    "    \"fnlwgt\": float,\n",
    "    \"capital-gain\": float,\n",
    "    \"capital-loss\": float,\n",
    "    \"hours-per-week\": float,\n",
    "    \"age\": float\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a94ed401-c1e0-47e9-b9f0-b5e5585efec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   age              48842 non-null  float64\n",
      " 1   workclass        48842 non-null  object \n",
      " 2   fnlwgt           48842 non-null  float64\n",
      " 3   education        48842 non-null  object \n",
      " 4   educational-num  48842 non-null  int64  \n",
      " 5   marital-status   48842 non-null  object \n",
      " 6   occupation       48842 non-null  object \n",
      " 7   relationship     48842 non-null  object \n",
      " 8   race             48842 non-null  object \n",
      " 9   gender           48842 non-null  object \n",
      " 10  capital-gain     48842 non-null  float64\n",
      " 11  capital-loss     48842 non-null  float64\n",
      " 12  hours-per-week   48842 non-null  float64\n",
      " 13  native-country   48842 non-null  object \n",
      " 14  income           48842 non-null  object \n",
      "dtypes: float64(5), int64(1), object(9)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea400432-0796-4706-9a8d-28c906627181",
   "metadata": {},
   "source": [
    "## **Build a model** [without Pipelines]\n",
    "\n",
    "In this case, we're building a model with the following steps:\n",
    "   1. Preprocessing\n",
    "      1. Transform categorical data with OHE\n",
    "      2. Transform numerical data with StandardScaler\n",
    "   2. Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c64c17f-5ebd-42f4-be60-b926f5030cb9",
   "metadata": {},
   "source": [
    "### **Prepare data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc5323f2-529f-498d-9665-2f4d8c5442f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"income\"])\n",
    "y = data[\"income\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd01f5d-d36c-4d78-ab8d-da9347db486f",
   "metadata": {},
   "source": [
    "### **Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb7a594-5c24-41d3-886d-22ea59051718",
   "metadata": {},
   "source": [
    "**Apply One-Hot-Encoging** to categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44f3050b-40cb-47f0-a119-6f80da078b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fing categorical columns\n",
    "X_train_cat = X_train.select_dtypes([\"O\",\"int\"])\n",
    "\n",
    "# apply OHE to categorical columns\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "X_train_cat = ohe.fit_transform(X_train_cat)\n",
    "\n",
    "X_train_cat = pd.DataFrame(X_train_cat, columns=ohe.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6735999-1fb9-43bc-9689-88a310531364",
   "metadata": {},
   "source": [
    "**Apply standardization** to numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad12c781-aab1-485d-b909-0ce57308ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num = X_train.select_dtypes([\"float\"])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_num = scaler.fit_transform(X_train_num)\n",
    "\n",
    "X_train_num = pd.DataFrame(X_train_num, columns=scaler.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba87cd2-129f-49cb-a3d1-d77b7f13245a",
   "metadata": {},
   "source": [
    "**Join both results in one table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7781151-0e53-40c3-b09c-a8e954c7a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = X_train_cat.join(X_train_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6065160b-52d9-4b2e-86fd-b9192682d8ce",
   "metadata": {},
   "source": [
    "### **Build the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60b6834e-a9b0-4d3c-923a-dcdceba3d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='liblinear', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28563bf0-d2ed-4866-8d0d-5bc9cb80ccfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 438 ms\n",
      "Wall time: 526 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, solver='liblinear')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf.fit(X_train_full, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202f2a59-c45b-4369-b581-74757fa968dd",
   "metadata": {},
   "source": [
    "### **Evaluate the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b90084d-482a-4eda-ac6c-15474030a351",
   "metadata": {},
   "source": [
    "#### **Evaluate on training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7acdd81-4c06-410f-8ed9-9f3b08ff5d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_train_full)\n",
    "probas = clf.predict_proba(X_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68c6d251-77ea-4f0f-9c3c-a6128ebdc003",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_test = precision_score(y_train, pred, pos_label=\">50K\")\n",
    "recall_test = recall_score(y_train, pred, pos_label=\">50K\")\n",
    "f1_test = f1_score(y_train, pred, pos_label=\">50K\")\n",
    "roc_auc_test = roc_auc_score(y_train, probas[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a0be408-e946-4108-b137-2645896a625e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision: 0.738\n",
      "Train Recall: 0.607\n",
      "Train F1: 0.666\n",
      "Train ROC_AUC: 0.909\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Precision: {round(precision_test,3)}\")\n",
    "print(f\"Train Recall: {round(recall_test,3)}\")\n",
    "print(f\"Train F1: {round(f1_test,3)}\")\n",
    "print(f\"Train ROC_AUC: {round(roc_auc_test,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c6f664-e1ed-4d57-9f7f-3f6f7a50e64e",
   "metadata": {},
   "source": [
    "#### **Evaluate on test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d41cf517-5a4f-46cd-bc90-c1b65086e39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply OHE to categorical columns\n",
    "X_test_cat = X_test.select_dtypes([\"O\",\"int\"])\n",
    "X_test_cat = ohe.transform(X_test_cat)\n",
    "X_test_cat = pd.DataFrame(X_test_cat, columns=ohe.get_feature_names_out())\n",
    "\n",
    "# apply stanrdadization also to the test\n",
    "X_test_num = X_test.select_dtypes([\"float\"])\n",
    "X_test_num = scaler.transform(X_test_num)\n",
    "X_test_num = pd.DataFrame(X_test_num, columns=scaler.get_feature_names_out())\n",
    "\n",
    "# join both tables\n",
    "X_test_full = X_test_cat.join(X_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbf1f6fe-571d-4795-be54-f2d817be4062",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test_full)\n",
    "probas = clf.predict_proba(X_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12826cda-5268-462f-8165-cde0ccccdb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_test = precision_score(y_test, pred, pos_label=\">50K\")\n",
    "recall_test = recall_score(y_test, pred, pos_label=\">50K\")\n",
    "f1_test = f1_score(y_test, pred, pos_label=\">50K\")\n",
    "roc_auc_test = roc_auc_score(y_test, probas[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bed1c0f-ec1b-4e87-9d05-57ef53541bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision: 0.721\n",
      "Test Recall: 0.599\n",
      "Test F1: 0.654\n",
      "Test ROC_AUC: 0.905\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Precision: {round(precision_test,3)}\")\n",
    "print(f\"Test Recall: {round(recall_test,3)}\")\n",
    "print(f\"Test F1: {round(f1_test,3)}\")\n",
    "print(f\"Test ROC_AUC: {round(roc_auc_test,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341f695a-8c73-494d-aceb-eee6569df594",
   "metadata": {},
   "source": [
    "## **Build a model** [with Pipelines]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51af8fbf-1a2d-43eb-b2bf-ed20089327e0",
   "metadata": {},
   "source": [
    "### **Prepare data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c84c3aa3-1798-432c-8c60-0a492d8e0f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"income\"])\n",
    "y = data[\"income\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c059f6-1d4b-4565-90c8-aef62282208a",
   "metadata": {},
   "source": [
    "### **Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb292eb-21c6-4d43-90a1-8852b65d1e5a",
   "metadata": {},
   "source": [
    "Build a **ColumnTransformer** with all the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3234abe-8fdf-44c1-99d8-17d5d8475342",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = X.select_dtypes([\"O\",\"int\"]).columns\n",
    "numerical_columns = X.select_dtypes([\"float\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1711a7f2-5e06-4f4b-af76-60764ecfc821",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        (\n",
    "            \"ohe\",\n",
    "            OneHotEncoder(sparse=False),\n",
    "            categorical_columns\n",
    "        ),\n",
    "        (\n",
    "            \"scaler\",\n",
    "            StandardScaler(),\n",
    "            numerical_columns\n",
    "        )\n",
    "    ],\n",
    "    remainder=\"drop\"  # this can be \"drop\", \"passthrough\", or another Estimator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "202f4817-47b5-45a2-a6c4-ecee5a34eb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can directly apply the OHE + scaler to original data\n",
    "X_train_full = preprocessing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b98337a1-a2a0-4181-a468-379458588593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to DataFrame\n",
    "X_train_full = pd.DataFrame(X_train_full, columns=preprocessing.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0cb4697a-1b29-4d6d-a845-4ff97a1f2b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ohe__workclass_?</th>\n",
       "      <th>ohe__workclass_Federal-gov</th>\n",
       "      <th>ohe__workclass_Local-gov</th>\n",
       "      <th>ohe__workclass_Never-worked</th>\n",
       "      <th>ohe__workclass_Private</th>\n",
       "      <th>ohe__workclass_Self-emp-inc</th>\n",
       "      <th>ohe__workclass_Self-emp-not-inc</th>\n",
       "      <th>ohe__workclass_State-gov</th>\n",
       "      <th>ohe__workclass_Without-pay</th>\n",
       "      <th>ohe__education_10th</th>\n",
       "      <th>...</th>\n",
       "      <th>ohe__native-country_Thailand</th>\n",
       "      <th>ohe__native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>ohe__native-country_United-States</th>\n",
       "      <th>ohe__native-country_Vietnam</th>\n",
       "      <th>ohe__native-country_Yugoslavia</th>\n",
       "      <th>scaler__age</th>\n",
       "      <th>scaler__fnlwgt</th>\n",
       "      <th>scaler__capital-gain</th>\n",
       "      <th>scaler__capital-loss</th>\n",
       "      <th>scaler__hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.487854</td>\n",
       "      <td>-1.453557</td>\n",
       "      <td>1.876761</td>\n",
       "      <td>-0.216957</td>\n",
       "      <td>1.584532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.044861</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>-0.146436</td>\n",
       "      <td>-0.216957</td>\n",
       "      <td>0.774555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.174099</td>\n",
       "      <td>-0.652381</td>\n",
       "      <td>0.271428</td>\n",
       "      <td>-0.216957</td>\n",
       "      <td>-0.035421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466044</td>\n",
       "      <td>-1.525541</td>\n",
       "      <td>-0.146436</td>\n",
       "      <td>3.482491</td>\n",
       "      <td>2.394508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.628752</td>\n",
       "      <td>-0.767670</td>\n",
       "      <td>-0.146436</td>\n",
       "      <td>-0.216957</td>\n",
       "      <td>-0.035421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ohe__workclass_?  ohe__workclass_Federal-gov  ohe__workclass_Local-gov  \\\n",
       "0               0.0                         0.0                       0.0   \n",
       "1               0.0                         0.0                       0.0   \n",
       "2               0.0                         0.0                       0.0   \n",
       "3               0.0                         0.0                       0.0   \n",
       "4               0.0                         0.0                       0.0   \n",
       "\n",
       "   ohe__workclass_Never-worked  ohe__workclass_Private  \\\n",
       "0                          0.0                     0.0   \n",
       "1                          0.0                     1.0   \n",
       "2                          0.0                     0.0   \n",
       "3                          0.0                     0.0   \n",
       "4                          0.0                     1.0   \n",
       "\n",
       "   ohe__workclass_Self-emp-inc  ohe__workclass_Self-emp-not-inc  \\\n",
       "0                          1.0                              0.0   \n",
       "1                          0.0                              0.0   \n",
       "2                          0.0                              1.0   \n",
       "3                          0.0                              1.0   \n",
       "4                          0.0                              0.0   \n",
       "\n",
       "   ohe__workclass_State-gov  ohe__workclass_Without-pay  ohe__education_10th  \\\n",
       "0                       0.0                         0.0                  0.0   \n",
       "1                       0.0                         0.0                  0.0   \n",
       "2                       0.0                         0.0                  0.0   \n",
       "3                       0.0                         0.0                  0.0   \n",
       "4                       0.0                         0.0                  0.0   \n",
       "\n",
       "   ...  ohe__native-country_Thailand  ohe__native-country_Trinadad&Tobago  \\\n",
       "0  ...                           0.0                                  0.0   \n",
       "1  ...                           0.0                                  0.0   \n",
       "2  ...                           0.0                                  0.0   \n",
       "3  ...                           0.0                                  0.0   \n",
       "4  ...                           0.0                                  0.0   \n",
       "\n",
       "   ohe__native-country_United-States  ohe__native-country_Vietnam  \\\n",
       "0                                1.0                          0.0   \n",
       "1                                1.0                          0.0   \n",
       "2                                1.0                          0.0   \n",
       "3                                1.0                          0.0   \n",
       "4                                1.0                          0.0   \n",
       "\n",
       "   ohe__native-country_Yugoslavia  scaler__age  scaler__fnlwgt  \\\n",
       "0                             0.0     1.487854       -1.453557   \n",
       "1                             0.0    -0.044861        0.005824   \n",
       "2                             0.0     0.174099       -0.652381   \n",
       "3                             0.0     0.466044       -1.525541   \n",
       "4                             0.0    -0.628752       -0.767670   \n",
       "\n",
       "   scaler__capital-gain  scaler__capital-loss  scaler__hours-per-week  \n",
       "0              1.876761             -0.216957                1.584532  \n",
       "1             -0.146436             -0.216957                0.774555  \n",
       "2              0.271428             -0.216957               -0.035421  \n",
       "3             -0.146436              3.482491                2.394508  \n",
       "4             -0.146436             -0.216957               -0.035421  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ec8e19-0df8-40ec-99f8-a8ac5e0b129f",
   "metadata": {},
   "source": [
    "### **Build the whole process**\n",
    "\n",
    "Now that we have defined the preprocessing step, we can use the `Pipeline` to chain the preprocessing and the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a17674e0-1ec0-4a52-8b91-fbea49869a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='liblinear', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ddec47b6-fc0a-4d5c-88fd-5a3293ee0ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessing\", preprocessing),\n",
    "        (\"classifier\", clf)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d736ecd-3338-439d-bff6-0be15fcb519e",
   "metadata": {},
   "source": [
    "### **Apply the whole process to original data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad80f01f-788c-4d36-9340-924c9d5d9129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 422 ms\n",
      "Wall time: 502 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  Index(['workclass', 'education', 'educational-num', 'marital-status',\n",
       "       'occupation', 'relationship', 'race', 'gender', 'native-country'],\n",
       "      dtype='object')),\n",
       "                                                 ('scaler', StandardScaler(),\n",
       "                                                  Index(['age', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week'], dtype='object'))])),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(max_iter=1000, solver='liblinear'))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f790fa-c04b-4fdb-94b2-60600426d833",
   "metadata": {},
   "source": [
    "### **Evaluate the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91640dd-8a93-479b-a68b-05ad9c30da93",
   "metadata": {},
   "source": [
    "#### **Evaluate on training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "60a80cf4-188e-4c2f-b8b3-c76f5863c3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_train)\n",
    "probas = model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4e35cab6-b087-40bc-9c1a-26ebf008b4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_test = precision_score(y_train, pred, pos_label=\">50K\")\n",
    "recall_test = recall_score(y_train, pred, pos_label=\">50K\")\n",
    "f1_test = f1_score(y_train, pred, pos_label=\">50K\")\n",
    "roc_auc_test = roc_auc_score(y_train, probas[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b7a2c12-3675-4830-bb2d-9223b9bb7600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision: 0.738\n",
      "Train Recall: 0.607\n",
      "Train F1: 0.666\n",
      "Train ROC_AUC: 0.909\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Precision: {round(precision_test,3)}\")\n",
    "print(f\"Train Recall: {round(recall_test,3)}\")\n",
    "print(f\"Train F1: {round(f1_test,3)}\")\n",
    "print(f\"Train ROC_AUC: {round(roc_auc_test,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be62a35-431a-40a0-8d14-d546c6df6152",
   "metadata": {},
   "source": [
    "#### **Evaluate on test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9873619c-4014-4be1-aa1f-c644c8494f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "probas = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04f216eb-1277-4feb-8a87-0d6bd4047dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_test = precision_score(y_test, pred, pos_label=\">50K\")\n",
    "recall_test = recall_score(y_test, pred, pos_label=\">50K\")\n",
    "f1_test = f1_score(y_test, pred, pos_label=\">50K\")\n",
    "roc_auc_test = roc_auc_score(y_test, probas[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c75cb6e-2ab6-4e21-a704-3555b5e0bcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision: 0.721\n",
      "Test Recall: 0.599\n",
      "Test F1: 0.654\n",
      "Test ROC_AUC: 0.905\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Precision: {round(precision_test,3)}\")\n",
    "print(f\"Test Recall: {round(recall_test,3)}\")\n",
    "print(f\"Test F1: {round(f1_test,3)}\")\n",
    "print(f\"Test ROC_AUC: {round(roc_auc_test,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112fcbc9-d062-4692-b86f-96aee393638b",
   "metadata": {},
   "source": [
    "### **Exercise:** Build the following pipeline\n",
    "\n",
    "1. Preprocessing\n",
    "   1. OHE to all columns except `workclass`\n",
    "   2. OrdinalEncoder for `workclass`\n",
    "   3. StandardScaler for all resulting columns + numerical ones\n",
    "2. Feature Selection technique (SelectKBest)\n",
    "3. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da0524d9-4332-4c55-8eca-b5524ccaeded",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data.drop([\"income\"],axis=1)\n",
    "y = data[\"income\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=99)\n",
    "\n",
    "Sc = StandardScaler()\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b7bb386-db67-4b5c-86b6-e39b6fc7e2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = X.select_dtypes([\"int\",\"O\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f70e310-c5e0-4892-a891-0ca07ef9360d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   age              48842 non-null  int64 \n",
      " 1   workclass        48842 non-null  object\n",
      " 2   fnlwgt           48842 non-null  int64 \n",
      " 3   education        48842 non-null  object\n",
      " 4   educational-num  48842 non-null  int64 \n",
      " 5   marital-status   48842 non-null  object\n",
      " 6   occupation       48842 non-null  object\n",
      " 7   relationship     48842 non-null  object\n",
      " 8   race             48842 non-null  object\n",
      " 9   gender           48842 non-null  object\n",
      " 10  capital-gain     48842 non-null  int64 \n",
      " 11  capital-loss     48842 non-null  int64 \n",
      " 12  hours-per-week   48842 non-null  int64 \n",
      " 13  native-country   48842 non-null  object\n",
      "dtypes: int64(6), object(8)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5256486f-4cab-4cc5-b0fe-24c156560775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        (\"ohe\", OneHotEncoder(sparse=False), cat_features.drop(\"workclass\")),\n",
    "        (\"ordinal\",OneHotEncoder(),[\"workclass\"] )\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c36d0a0a-8910-4234-afd4-e45c98d12f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Pipeline(\n",
    "    [\n",
    "        (\"cat_preprocessing\", cat_preprocessing),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20375224-8843-4b96-a142-e0c3b2ca574f",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea68f0c6-e493-4e31-93ed-9e806aaa6bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps.append((\"preprocessing\", preprocessing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d3380cb-2826-4eb5-9b17-9ba9d3df8e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "fs = SelectKBest(score_func=f_classif, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51039ea8-8ef0-4879-b73a-f2663d9c9cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps.append((\"feature_selection\", fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afc1f39d-ee99-4984-a5ff-c7549f619529",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "search_space = {\n",
    "    \"C\": np.logspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e392e32-546a-4ee1-ba2b-57f3ca5f2e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps.append((\"model\", lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1eda3cfd-777d-4f20-89cc-8d60b0efede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = Pipeline(steps =steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "240c4fd5-b820-4525-93d4-abb6d3250381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 Pipeline(steps=[('cat_preprocessing',\n",
       "                                  ColumnTransformer(remainder='passthrough',\n",
       "                                                    transformers=[('ohe',\n",
       "                                                                   OneHotEncoder(sparse=False),\n",
       "                                                                   Index(['age', 'fnlwgt', 'education', 'educational-num', 'marital-status',\n",
       "       'occupation', 'relationship', 'race', 'gender', 'capital-gain',\n",
       "       'capital-loss', 'hours-per-week', 'native-country'],\n",
       "      dtype='object')),\n",
       "                                                                  ('ordinal',\n",
       "                                                                   OneHotEncoder(),\n",
       "                                                                   ['workclass'])])),\n",
       "                                 ('scaler', StandardScaler())])),\n",
       "                ('feature_selection', SelectKBest()),\n",
       "                ('model', LogisticRegression())])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a73e2ad6-7a84-4a11-8a9b-194f6977f90b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfinal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:756\u001b[0m, in \u001b[0;36mPipeline.get_feature_names_out\u001b[1;34m(self, input_features)\u001b[0m\n\u001b[0;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transform, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_feature_names_out\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    751\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    752\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimator \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m does not provide get_feature_names_out. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    753\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDid you mean to call pipeline[:-1].get_feature_names_out\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    754\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m()?\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name)\n\u001b[0;32m    755\u001b[0m         )\n\u001b[1;32m--> 756\u001b[0m     feature_names_out \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_names_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m feature_names_out\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:756\u001b[0m, in \u001b[0;36mPipeline.get_feature_names_out\u001b[1;34m(self, input_features)\u001b[0m\n\u001b[0;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transform, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_feature_names_out\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    751\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    752\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimator \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m does not provide get_feature_names_out. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    753\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDid you mean to call pipeline[:-1].get_feature_names_out\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    754\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m()?\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name)\n\u001b[0;32m    755\u001b[0m         )\n\u001b[1;32m--> 756\u001b[0m     feature_names_out \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_names_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m feature_names_out\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:475\u001b[0m, in \u001b[0;36mColumnTransformer.get_feature_names_out\u001b[1;34m(self, input_features)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_feature_names_out\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    457\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get output feature names for transformation.\u001b[39;00m\n\u001b[0;32m    458\u001b[0m \n\u001b[0;32m    459\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m        Transformed feature names.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m     input_features \u001b[38;5;241m=\u001b[39m _check_feature_names_in(\u001b[38;5;28mself\u001b[39m, input_features)\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;66;03m# List of tuples (name, feature_names_out)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1222\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1217\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1218\u001b[0m         v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1219\u001b[0m     ]\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted:\n\u001b[1;32m-> 1222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "\n",
    "final.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480b9d81-2311-4b8a-80fc-ee767bee2d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
