{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"200\" style=\"float:left\" \n",
    "     src=\"https://upload.wikimedia.org/wikipedia/commons/f/f3/Apache_Spark_logo.svg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"display: block;max-height:100px;float:left\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/08/Netflix_2015_logo.svg/2560px-Netflix_2015_logo.svg.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sections\n",
    "* [Description](#0)\n",
    "* [1. Setup](#1)\n",
    "  * [1.1 Start Hadoop](#1.1)  \n",
    "  * [1.2 Search for Spark Installation](#1.2)\n",
    "  * [1.3 Create SparkSession](#1.3)\n",
    "* [2. Lab](#2)\n",
    "  * [2.1 Check Lab Files](#2.1)\n",
    "* [3. Data Exploration](#3)  \n",
    "* [4. Collaborative Filtering](#4)\n",
    "* [5. Recommendations](#5)\n",
    "* [6. TearDown](#6)\n",
    "  * [6.1 Stop Hadoop](#6.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "## Description\n",
    "<p>\n",
    "<p>One of the most common uses of big data is to predict what users want. \n",
    "This allows Google to show you relevant ads, Amazon to recommend relevant products, and Netflix to recommend movies that you might like. \n",
    "</p>\n",
    "In thi lab we will use Apache Spark to recommend movies to a user.     \n",
    "<div>The goal for this lab are:</div>\n",
    "<ul>    \n",
    "    <li>Practice the Spark ML API</li>\n",
    "    <li>Exploring the dataset</li>\n",
    "    <li>Build a Collaborative Filtering model</li>\n",
    "    <li>Make customized movie predictions for you ðŸ˜‰</li>\n",
    "</ul>    \n",
    "</p>\n",
    "\n",
    "[Youtube Video](https://www.youtube.com/watch?v=FgGjc5oabrA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "## 1. Setup\n",
    "\n",
    "Since we are going to process data stored from HDFS let's start the service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.1'></a>\n",
    "### 1.1 Start Hadoop\n",
    "\n",
    "Start Hadoop\n",
    "\n",
    "Open a terminal and execute\n",
    "```sh\n",
    "hadoop-start.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2'></a>\n",
    "### 1.2 Search for Spark Installation \n",
    "This step is required just because we are working in the course environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm changing pandas max column width property to improve data displaying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.3'></a>\n",
    "### 1.3 Create SparkSession\n",
    "\n",
    "By setting this environment variable we can include extra libraries in our Spark cluster.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = ' pyspark-shell'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing always is to create the SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "    .appName(\"Movielens - Movie Recommendere - MLlib\")\n",
    "    .config(\"spark.sql.warehouse.dir\",\"hdfs://localhost:9000/warehouse\")\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "## 2. Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=FgGjc5oabrA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1'></a>\n",
    "### 2.1 Check Lab Files\n",
    "\n",
    "In order to complete this lab you need to previosly upload the datasets into HDFS.<br/>\n",
    "\n",
    "Check you have the data ready in HDFS\n",
    "\n",
    "http://localhost:50070/explorer.html#/datalake/std/movielens/ratings/\n",
    "\n",
    "http://localhost:50070/explorer.html#/datalake/std/movielens/movies/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 3. Data Exploration\n",
    "\n",
    "We're going to be accessing this data a lot. \n",
    "\n",
    "Rather than reading it from source over and over again, we'll cache both the movies DataFrame and the ratings DataFrame into the executor's memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = spark.read.parquet(\"hdfs://localhost:9000/datalake/std/movielens/movies/\").cache()\n",
    "print(f\"There are {movies.count()} movies in the datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = spark.read.parquet(\"hdfs://localhost:9000/datalake/std/movielens/ratings/\").cache()\n",
    "print(f\"There are {ratings.count()} rating in the datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at some of the data in the two DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "## 4. Collaborative Filtering\n",
    "\n",
    "Before we jump into using machine learning, we need to break up the `ratingsDF` dataset into two DataFrames:\n",
    "* A training set, which we will use to train models\n",
    "* A test set, which we will use for our experiments\n",
    "\n",
    "To randomly split the dataset into the multiple groups, we can use the [randomSplit()](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.randomSplit.html?highlight=randomsplit#pyspark.sql.DataFrame.randomSplit) transformation. `randomSplit()` takes a set of splits and a seed and returns multiple DataFrames. Use the seed given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll hold out 80% for training and leave 20% for testing \n",
    "seed = 42\n",
    "(trainingDF, testDF) = ratings.randomSplit([0.8, 0.2], seed=seed)\n",
    "\n",
    "print(f\"Training: {trainingDF.count()}, test: {testDF.count()}\")\n",
    "trainingDF.show(3)\n",
    "testDF.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Baseline Model\n",
    "\n",
    "Let's calculate the average movie rating in our dataset to use as our baseline model.\n",
    "\n",
    "Because we are trying to predict a rating (a number) this is a **regression** problem and we need to use a regression metric in order to evalute the performacen of the model.\n",
    "\n",
    "We are going to use the **RMSE** (**R**oot **M**ean **S**quared **E**rror). The lower the error we get, the better the model it is.\n",
    "\n",
    "Let's calculate it for the baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "rmseEvaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"rating\", metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, avg\n",
    "\n",
    "averageRating = trainingDF.select(avg(\"rating\")).first()[0]\n",
    "\n",
    "baselineDF = trainingDF.withColumn(\"prediction\", lit(averageRating))\n",
    "\n",
    "baselineRmse = rmseEvaluator.evaluate(baselineDF)\n",
    "\n",
    "print(f\"Baseline RMSE: {baselineRmse:.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Alternating Least Squares\n",
    "\n",
    "Now we will use the Apache Spark ML Pipeline implementation of Alternating Least Squares, [ALS (Python)](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.recommendation.ALS.html?highlight=als#pyspark.ml.recommendation.ALS). \n",
    "\n",
    "To determine the best values for the hyperparameters, we will use ALS to train several models, and then we will select the best model and use the parameters from that model in the rest of this lab exercise.\n",
    "\n",
    "The process we will use for determining the best model is as follows:\n",
    "1. Pick a set of model parameters. The most important parameter to model is the *rank*, which is the number of columns in the Users matrix or the number of rows in the Movies matrix. In general, a lower rank will mean higher error on the training dataset, but a high rank may lead to [overfitting](https://en.wikipedia.org/wiki/Overfitting).We will train models with ranks of 4 and 12 using the `trainingDF` dataset.\n",
    "\n",
    "\n",
    "2. Set the appropriate parameters on the `ALS` object:\n",
    "    * The \"User\" column will be set to the values in our `userId` DataFrame column.\n",
    "    * The \"Item\" column will be set to the values in our `movieId` DataFrame column.\n",
    "    * The \"Rating\" column will be set to the values in our `rating` DataFrame column.\n",
    "    * `nonnegative` = True (whether to use nonnegative constraint for least squares)\n",
    "    * `regParam` = 0.1.\n",
    "    \n",
    "   **Note**: Read the documentation for the ALS class **carefully**. It will help you accomplish this step.\n",
    "   \n",
    "\n",
    "3. Create multiple models using the `ParamGridBuilder` and the `CrossValidator`, one for each of our rank values.\n",
    "\n",
    "\n",
    "4. We'll keep the model with the lowest error rate. Such a model will be selected automatically by the CrossValidator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als = ALS(userCol=\"userId\",\n",
    "          itemCol=\"movieId\",\n",
    "          ratingCol=\"rating\",\n",
    "          maxIter=5,\n",
    "          seed=seed,\n",
    "          coldStartStrategy=\"drop\",\n",
    "          regParam=0.1,\n",
    "          nonnegative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.3'></a>\n",
    "### 4.3. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have initialized the algorithm, we need to fit it to our training data, and evaluate how well it does on the validation dataset. \n",
    "\n",
    "Let's create a `CrossValidator` and `ParamGridBuilder` that will decide whether *rank* value *4* or *12* gives a lower *RMSE*.  \n",
    "\n",
    "NOTE: This cell may take a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import *\n",
    "\n",
    "grid = (ParamGridBuilder()\n",
    "        .addGrid(als.rank, [4, 12]) \n",
    "        .build())\n",
    "\n",
    "cv = CrossValidator(numFolds=3, estimator=als, estimatorParamMaps=grid, evaluator=rmseEvaluator, seed=seed)          \n",
    "\n",
    "cvModel = cv.fit(trainingDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the model ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cvModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two ALS models were trained as we use a grid of 2 parameters. Let's check the RMSE errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model has a sligthly lower RMSE. Let's check it corresponds with option rank=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = cvModel.bestModel\n",
    "print(f\"The best model was trained with rank {bestModel.rank}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Model Evaluation\n",
    "\n",
    "So far, we used the `trainingDF` dataset to evalute the two models (baseline and ALS). \n",
    "\n",
    "Since we used this dataset to determine what model is best, we cannot use it to test how good the model is; otherwise, we would be very vulnerable to [overfitting](https://en.wikipedia.org/wiki/Overfitting).\n",
    "\n",
    "To decide how good our model is, we need to use the `testDF` dataset.  \n",
    "\n",
    "We will use the best model we just created for predicting the ratings for the test dataset and then we will compute the RMSE.\n",
    "\n",
    "The steps you should perform are:\n",
    "* Run a prediction, using `bestModel` as created above, on the test dataset (`testDF`), producing a new `predictedTestDF` DataFrame.\n",
    "* Use the previously created RMSE evaluator, `rmseEvaluator` to evaluate the filtered DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsBestModelDF = bestModel.transform(testDF)\n",
    "\n",
    "# Run the previously created RMSE evaluator\n",
    "alsRMSE = rmseEvaluator.evaluate(predictionsBestModelDF)\n",
    "\n",
    "print(f\"ALS RMSE: {alsRMSE:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionBaselineModelDF = testDF.withColumn(\"prediction\", lit(averageRating))\n",
    "\n",
    "baselineRMSE = rmseEvaluator.evaluate(predictionBaselineModelDF)\n",
    "\n",
    "print(f\"Baseline RMSE: {baselineRMSE:.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "## 5. Recommendations\n",
    "\n",
    "The last point of this lab exercise is to predict what movies to recommend to yourself.  \n",
    "\n",
    "In order to do that, you will first need to add ratings for yourself to the `ratingsDF` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Movie Ratings\n",
    "\n",
    "To help you provide ratings for yourself, I have included the following code to list the names and movieIds of the 100 highest-rated movies that have at least 100 ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.createOrReplaceTempView(\"movies\")\n",
    "ratings.createOrReplaceTempView(\"ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100RatedMovies = spark.sql(\"\"\"\n",
    "                                SELECT r.movieId, m.title, AVG(rating) AS avg_rating, COUNT(*) AS num_ratings\n",
    "                                FROM ratings r JOIN movies m ON (r.movieId = m.movieId)\n",
    "                                GROUP BY r.movieId, m.title\n",
    "                                HAVING COUNT(*) > 100\n",
    "                                ORDER BY avg_rating DESC\n",
    "                                LIMIT 100\n",
    "                                \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_rows', 20)\n",
    "top100RatedMovies.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user ID 0 is unassigned, so we will use it for your ratings. We set the variable `myUserId` to 0 for you. \n",
    "\n",
    "Next, create a new DataFrame called `myRatingsDF`, with your ratings for at least 10 movie ratings. Each entry should be formatted as `(myUserId, movieId, rating)`.  As in the original dataset, ratings should be between 1 and 5 (inclusive). \n",
    "\n",
    "If you have not seen at least 10 of these movies, you can increase the parameter passed to `LIMIT` in the above cell until there are 10 movies that you have seen (or you can also guess what your rating would be for movies you have not seen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "myUserId = 0\n",
    "now = datetime.now()\n",
    "myRatedMovies = [\n",
    "     (myUserId, 1214, 5, now), # Alien\n",
    "     (myUserId, 480,  5, now), # Jurassic Park\n",
    "     (myUserId, 260, 5, now),  # Star Wars: Episode IV - A New Hope\n",
    "     (myUserId, 541, 5, now),  # Blade Runner\n",
    "     (myUserId, 2571, 5, now), # Matrix, The\n",
    "     (myUserId, 296,  5, now), # Pulp Fiction\n",
    "     (myUserId, 356,  5, now), # Forrest Gump     \n",
    "     (myUserId, 593, 5, now),  # Silence of the Lambs, The\n",
    "]\n",
    "\n",
    "myRatingsDF = spark.createDataFrame(myRatedMovies, ['userId', 'movieId', 'rating','timestamp'])\n",
    "myRatingsDF.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.join(myRatingsDF,\"movieId\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Add Your Movies to Training Dataset\n",
    "\n",
    "Now that you have ratings for yourself, you need to add your ratings to the `trainingDF` dataset so that the model you train will incorporate your preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingWithMyRatingsDF = trainingDF.unionByName(myRatingsDF)\n",
    "\n",
    "countDiff = trainingWithMyRatingsDF.count() - trainingDF.count()\n",
    "print(f\"The training dataset now has {countDiff} more entries than the original training dataset\")\n",
    "assert (countDiff == myRatingsDF.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Model with Your Ratings\n",
    "\n",
    "Now, train a model with your ratings added and the parameters you used in in part (2b) and (2c). Make sure you include all of the parameters.\n",
    "\n",
    "Note: This cell will take about 1 minute to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als.setRank(12)\n",
    "myRatingsModel = als.fit(trainingWithMyRatingsDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Your Ratings\n",
    "\n",
    "Now that we have trained a new model, let's predict what ratings you would give to the movies that you did not already provide ratings for. The code below filters out all of the movies you have rated, and creates a `predictedRatingsDF` DataFrame of the predicted ratings for all of your unseen movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the my rated movieIds\n",
    "myRatedMovieIds = [x[1] for x in myRatedMovies]\n",
    "\n",
    "# Filter out the movies I already rated.\n",
    "notRatedDF = movies.filter(~ movies['movieId'].isin(myRatedMovieIds))\n",
    "\n",
    "# Add a column with myUserId as \"userId\".\n",
    "myUnratedMoviesDF = notRatedDF.withColumn('userId', lit(myUserId))       \n",
    "\n",
    "# Use myRatingModel to predict ratings for the movies that I did not manually rate.\n",
    "predictedRatingsDF = myRatingsModel.transform(myUnratedMoviesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedRatingsDF.createOrReplaceTempView(\"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedRatingsDF.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create two more DataFrames to get links and trailers for the movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = spark.read.parquet(\"hdfs://localhost:9000/datalake/std/movielens/links/\").cache()\n",
    "trailers = spark.read.parquet(\"hdfs://localhost:9000/datalake/std/movielens/trailers/\").cache()\n",
    "\n",
    "links.createOrReplaceTempView(\"links\")\n",
    "trailers.createOrReplaceTempView(\"trailers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trailers.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets' create a function to get the recommendations for any user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField,IntegerType\n",
    "\n",
    "def get_recs(userId,recs_number=5) :\n",
    "    query = f\"\"\"\n",
    "        SELECT a.movieId,\n",
    "               a.title,\n",
    "               a.your_predicted_rating,\n",
    "               l.imdbUrl,\n",
    "               l.tmdbUrl,\n",
    "               t.youtubeUrl\n",
    "        FROM\n",
    "        (SELECT p.movieId,\n",
    "                p.title,               \n",
    "                p.prediction AS your_predicted_rating\n",
    "        FROM ratings r \n",
    "        INNER JOIN predictions p ON (r.movieId = p.movieId)        \n",
    "        WHERE p.userId = {userId}\n",
    "        GROUP BY p.movieId, p.title, p.prediction\n",
    "        HAVING COUNT(*) > 75\n",
    "        ORDER BY p.prediction DESC\n",
    "        LIMIT {recs_number}\n",
    "        ) a\n",
    "        LEFT JOIN links l ON a.movieId=l.movieId\n",
    "        LEFT JOIN trailers t ON a.movieId=t.movieId\n",
    "        \"\"\"\n",
    "    return spark.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print out the 10 movies with the highest predicted ratings for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myRecs = get_recs(userId=0,recs_number=10)\n",
    "myRecs.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Your Recommendations (Optional)\n",
    "\n",
    "To display the recommendations we are going to fetch the movie poster from IMBD website.<br/>\n",
    "We need to install this library. Open a terminal and execute the following command:\n",
    "\n",
    "```sh\n",
    "pip3 install beautifulsoup4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import HTML\n",
    "\n",
    "def fetch_movie_poster(url):\n",
    "    html = urllib.request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html)\n",
    "    for meta in soup.findAll(\"meta\"):\n",
    "        if 'property' in meta.attrs and meta.attrs['property'] == \"og:image\":\n",
    "            return meta.attrs['content']\n",
    "    return None\n",
    "\n",
    "def display_posters(recs):\n",
    "    html = \"<table><tr>\"\n",
    "    for rec in recs:\n",
    "        url=fetch_movie_poster(rec.imdbUrl)\n",
    "        html+=f'<td>'\n",
    "        html+=f'<img src=\"{url}\" width=\"100\"/>'\n",
    "        html+=f'<a style=\"text-align: center\" href=\"{rec.imdbUrl}\">(IMDB)</a><br/>'\n",
    "        html+=f'<a style=\"text-align: center\" href=\"{rec.tmdbUrl}\">(TMDB)</a>'\n",
    "        html+='</td>'\n",
    "    html+= \"</tr></table>\"    \n",
    "    display(HTML(html)) \n",
    "    \n",
    "def display_recs(recs):\n",
    "    html = \"\"\n",
    "    for rec in recs:        \n",
    "        html += f'<iframe src=\"{rec.youtubeUrl}\"></iframe>'\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_posters(myRecs.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_recs(myRecs.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "## 6. Tear Down\n",
    "\n",
    "Once we complete the the lab we can stop all the services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.1'></a>\n",
    "### 6.1 Stop Hadoop\n",
    "\n",
    "Stops Hadoop\n",
    "Open a terminal and execute\n",
    "```sh\n",
    "hadoop-stop.sh\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
