{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Assignment: Machine Learning 2\n",
    "\n",
    "This year's Group Assignment will verse on predicting employee attrition. The dataset is available on Kaggle: [Employee Attrition competition](https://www.kaggle.com/competitions/playground-series-s3e3/data)\n",
    "\n",
    "* The goal is to predict whether an employee will leave the company or not (`Attrition` column, binary classification).\n",
    "* The dataset is artificially generated, but it is based on real data: [original data](https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset)\n",
    "    * Here you can find what each feature represents and their possible values.\n",
    "* You're given a training set and a test set. \n",
    "    * Perform your analysis, experiments and model selection on the training set, and don't touch the test set until you're ready to submit your predictions.\n",
    "    * You can save some data from the training set to use as a validation set, but you should not use the test set for this purpose.\n",
    "    * Once you're comfortable with the performance of your model on the training set, you can use the test set to get a final estimate of the performance of your model.\n",
    "    * The CSV file that you will submit, should contain the predictions of your model on the test set. This means that the CSV should contain as many rows as the test set, and a single column with the predictions (0 or 1)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Rules\n",
    "\n",
    "* You should work within your team. If I see any signs of cheating between teams, that's and immediate fail for both groups.\n",
    "  * If you have any question, post it on Slack and I will answer it as soon as possible.\n",
    "* The grade will be the same for all the members of the team.\n",
    "* Everyone within the team should contribute and all of you will have to either present or answer questions during the presentation.\n",
    "  * If somebody in the team is not collaborating, let me know as soon as possible since I will not accept any excuses at the end of the term\n",
    "  * Help the others in the team to understand the code and the results, because they might be asked to explain it during the presentation\n",
    "* It's fine to explore and learn from out there. \n",
    "  * I want to see that you are learning and that you are trying to improve your skills. However, you should not just copy-paste code from other sources -tell me where is it from and show me it's useful for your assignment-\n",
    "  * If you just copy and paste, I will know and I will ask you about it, so be prepared.\n",
    "* The final submission should use any of the algorithms that we've seen during the course, so no neural networks or similar. There's will be a time for that, but not now.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Submission\n",
    "\n",
    "**1 ZIP file per group, named `submission_group_X.zip`, containing:**\n",
    "  * A Jupyter Notebook with the code and the results, mandatory to include the names of the members of the team.\n",
    "  * A PDF file with the presentation.\n",
    "  * A CSV file with the predictions for the test set.\n",
    "  * Failing to submit any of the above in the required conditions will result in a 0 for the Group Assignment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Grade\n",
    "\n",
    "The Group Assignment will weight 40% of the final grade. The grade will be based on the following criteria:\n",
    "* **40%: PDF report and presentation**\n",
    "    * The report should be done for an executive audience, so don't go too much into the technical details underneath the algorithms. \n",
    "    * It should cover a brief exploration of the data, the experiments done regarding feature engineering and the algorithms used, the results and the conclusions.\n",
    "    * For the presentation, I will choose somebody from the team to present.\n",
    "* **30%: Code in Jupyter notebook**\n",
    "    * Comment why you're doing what you're doing.\n",
    "    * Document your experiments and the results in the notebook.\n",
    "    * Make sure that you do all your `import`s at the beginning of the notebook, so that I know what packages you're using. If your code doesn't run, I will not grade it fully.\n",
    "* **30%: Answers to my questions during the presentation**\n",
    "    * There will be questions about the data and its exploration, the experiments done with the features and with the algorithms, and obviously about the performance and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "import pandas_profiling\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "import plotly.express as px\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/mac/Desktop/group_assignment_ML2/data/train.csv', sep = \",\")\n",
    "test = pd.read_csv('/Users/mac/Desktop/group_assignment_ML2/data/test.csv', sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_names</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.811115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.842245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.865791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.866999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_names       auc\n",
       "0  Logistic Regression  0.811115\n",
       "1        Random Forest  0.842245\n",
       "2    Gradient Boosting  0.865791\n",
       "3        XGBClassifier  0.866999"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= train.drop([\"Attrition\"],axis=1)\n",
    "y = train[\"Attrition\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=99)\n",
    "\n",
    "Sc = StandardScaler()\n",
    "ohe = OneHotEncoder()\n",
    "numeric_features = [\"Age\",\"DailyRate\",\"DistanceFromHome\",\"Education\",\"HourlyRate\",\"JobLevel\",\"MonthlyIncome\",\"MonthlyRate\",\"NumCompaniesWorked\",\"PercentSalaryHike\",\n",
    "                    \"TotalWorkingYears\",\"TrainingTimesLastYear\",\"YearsAtCompany\",\"YearsInCurrentRole\",\"YearsSinceLastPromotion\",\"YearsWithCurrManager\"]\n",
    "categorical_features = [\"BusinessTravel\",\"Gender\",\"Department\",\"MaritalStatus\",\"EducationField\",\"JobRole\",\"OverTime\",\"WorkLifeBalance\"]\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "                ('num', Sc, numeric_features),\n",
    "                ('cat', ohe, categorical_features)])\n",
    "\n",
    "models=[LogisticRegression(solver=\"liblinear\",max_iter=1000),RandomForestClassifier(),GradientBoostingClassifier(random_state=99,learning_rate=0.05,max_depth=2,n_estimators=200),xgb.XGBClassifier(random_state=99,learning_rate=0.05,max_depth=2,n_estimators=200)]\n",
    "\n",
    "\n",
    "auc=[]\n",
    "\n",
    "for x in models:\n",
    "    model = Pipeline(steps=[('preprocess', preprocess),\n",
    "                            ('model', x)])\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    auc.append(roc_auc)\n",
    "\n",
    "model_names = ['Logistic Regression', 'Random Forest','Gradient Boosting',\"XGBClassifier\"]\n",
    "scores= pd.DataFrame({'model_names': model_names,\n",
    "                      \"auc\":auc})\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.8669991260089456\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "print(\"auc: \",roc_auc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1092, 1: 27})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred_test = model.predict(test)\n",
    "Counter(y_pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BERENGUER",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
